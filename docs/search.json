[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is Project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nAndrew Wang\n\n\nApr 21, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "This is Project 1"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrew Wang",
    "section": "",
    "text": "I currently study at UC San Diego within the MSBA program and am currently looking for a full-time job to be a Data/Business Analyst. With an undergraduate at UC San Diego in Mathematics: Probability & Statistics, I strive to apply my statistics background when analyzing data trends and ultimately providing data-driven business decisions."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/hw1_questions.html",
    "href": "blog/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007.Standard Letter was a regular appeal without mention of any matching funds. Matching Grant was a letter stating that contributions would be matched dollar-for-dollar (or at different match ratios such as 2:1 or 3:1) by a lead donor. Challenge Grant was a letter stating that the lead donor would only contribute if enough donations were received from others.The goal was to test both behavioral economic predictions (such as social pressure or anchoring) and standard economic theory regarding how incentives affect giving behavior. The randomized design ensures that differences in donation behavior across groups can be causally attributed to the letter variation. The results provided key insights into fundraising strategy and the psychology of donors, with implications for both nonprofits and economic theory on altruism. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "blog/hw1_questions.html#introduction",
    "href": "blog/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007.Standard Letter was a regular appeal without mention of any matching funds. Matching Grant was a letter stating that contributions would be matched dollar-for-dollar (or at different match ratios such as 2:1 or 3:1) by a lead donor. Challenge Grant was a letter stating that the lead donor would only contribute if enough donations were received from others.The goal was to test both behavioral economic predictions (such as social pressure or anchoring) and standard economic theory regarding how incentives affect giving behavior. The randomized design ensures that differences in donation behavior across groups can be causally attributed to the letter variation. The results provided key insights into fundraising strategy and the psychology of donors, with implications for both nonprofits and economic theory on altruism. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "blog/hw1_questions.html#data",
    "href": "blog/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset comprises 50,083 observations and 51 variables from a large-scale field experiment conducted by Karlan and List (2007) to study charitable giving behavior. Each row represents an individual donor who received one of several versions of a fundraising letter. The variables include binary indicators for treatment assignment (treatment, control), experimental conditions such as match ratio (ratio, ratio2, ratio3) and match threshold (size, size25, size50, size100, sizeno), as well as customized donation suggestions (ask, askd1, askd2, askd3).\nDonation behavior is captured through variables like amount (the donation amount), gave (whether a donation was made), and amountchange (change from prior donation levels). Historical donation behavior is also recorded, including past frequency (freq), recency (years, dormant), and donor history (hpa, mrm2, ltmedmra). Demographic and geographic context is richly detailed with fields such as female, couple, state50one, and nonlit, along with state-level political and socioeconomic indicators (e.g., perbush, red0, median_hhincome, powner, psch_atlstba, pop_propurban).\nThe dataset is well-structured for causal analysis, containing a mixture of binary, categorical, and continuous variables. While most fields are complete, a few demographic columns (e.g., female, couple, pwhite) have some missing values. Overall, this dataset provides a robust foundation for replicating and extending the original experimental findings.\n\n\nLoad and Inspect the Data\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(knitr)\n\n# Load the data\ndf &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# Preview structure of the data\nneat_glimpse &lt;- function(df, n = 5) {\n  library(dplyr)\n  library(knitr)\n\n  df %&gt;%\n    summarise(across(everything(), typeof)) %&gt;%\n    pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Type\") %&gt;%\n    mutate(\n      Example = sapply(df, function(x) paste0(head(x, n), collapse = \", \"))\n    ) %&gt;%\n    kable(caption = \"Clean Summary of Dataset Variables\", align = \"lll\")\n}\nneat_glimpse(df)\n\n\nClean Summary of Dataset Variables\n\n\n\n\n\n\n\nVariable\nType\nExample\n\n\n\n\ntreatment\ndouble\n0, 0, 1, 1, 1\n\n\ncontrol\ndouble\n1, 1, 0, 0, 0\n\n\nratio\ndouble\n0, 0, 1, 1, 1\n\n\nratio2\ndouble\n0, 0, 0, 0, 0\n\n\nratio3\ndouble\n0, 0, 0, 0, 0\n\n\nsize\ndouble\n0, 0, 3, 4, 2\n\n\nsize25\ndouble\n0, 0, 0, 0, 0\n\n\nsize50\ndouble\n0, 0, 0, 0, 1\n\n\nsize100\ndouble\n0, 0, 1, 0, 0\n\n\nsizeno\ndouble\n0, 0, 0, 1, 0\n\n\nask\ndouble\n0, 0, 1, 1, 1\n\n\naskd1\ndouble\n0, 0, 1, 1, 1\n\n\naskd2\ndouble\n0, 0, 0, 0, 0\n\n\naskd3\ndouble\n0, 0, 0, 0, 0\n\n\nask1\ndouble\n55, 25, 55, 55, 35\n\n\nask2\ndouble\n70, 35, 70, 70, 45\n\n\nask3\ndouble\n85, 50, 85, 85, 55\n\n\namount\ndouble\n0, 0, 0, 0, 0\n\n\ngave\ndouble\n0, 0, 0, 0, 0\n\n\namountchange\ndouble\n-45, -25, -50, -25, -15\n\n\nhpa\ndouble\n45, 25, 50, 50, 25\n\n\nltmedmra\ndouble\n0, 1, 0, 1, 1\n\n\nfreq\ndouble\n2, 2, 3, 15, 42\n\n\nyears\ndouble\n4, 3, 2, 8, 95\n\n\nyear5\ndouble\n0, 0, 0, 1, 1\n\n\nmrm2\ndouble\n31, 5, 6, 1, 24\n\n\ndormant\ndouble\n1, 0, 0, 0, 1\n\n\nfemale\ndouble\n0, 0, 0, 0, 1\n\n\ncouple\ndouble\n0, 0, 0, 0, 0\n\n\nstate50one\ndouble\n0, 0, 0, 0, 0\n\n\nnonlit\ndouble\n5, 0, 3, 1, 1\n\n\ncases\ndouble\n4, 2, 1, 2, 1\n\n\nstatecnt\ndouble\n4.50029945373535, 2.9822461605072, 9.60702133178711, 3.28146815299988, 2.30201482772827\n\n\nstateresponse\ndouble\n0.0199468079954386, 0.0260869562625885, 0.023048173636198, 0.0206686928868294, 0.0155979199334979\n\n\nstateresponset\ndouble\n0.0195023529231548, 0.0278330016881227, 0.0221589114516973, 0.0247026532888412, 0.0169712789356709\n\n\nstateresponsec\ndouble\n0.0208062417805195, 0.022494887933135, 0.0247435122728348, 0.0126811591908336, 0.0128865977749228\n\n\nstateresponsetminc\ndouble\n-0.00130388885736465, 0.00533811375498772, -0.00258460082113743, 0.0120214940980077, 0.004084681160748\n\n\nperbush\ndouble\n0.490000009536743, 0.464646458625793, 0.408163279294968, 0.464646458625793, 0.525252521038055\n\n\nclose25\ndouble\n1, 0, 0, 0, 0\n\n\nred0\ndouble\n0, 0, 0, 0, 1\n\n\nblue0\ndouble\n1, 1, 1, 1, 0\n\n\nredcty\ndouble\n0, 1, 0, 1, 0\n\n\nbluecty\ndouble\n1, 0, 1, 0, 1\n\n\npwhite\ndouble\n0.446493446826935, NA, 0.935706436634064, 0.888330936431885, 0.759014070034027\n\n\npblack\ndouble\n0.527769207954407, NA, 0.0119483657181263, 0.0107604013755918, 0.127420946955681\n\n\npage18_39\ndouble\n0.317591279745102, NA, 0.276128172874451, 0.279411762952805, 0.442388862371445\n\n\nave_hh_sz\ndouble\n2.09999990463257, NA, 2.48000001907349, 2.65000009536743, 1.85000002384186\n\n\nmedian_hhincome\ndouble\n28517, NA, 51175, 79269, 40908\n\n\npowner\ndouble\n0.499807178974152, NA, 0.721940577030182, 0.92043137550354, 0.416072070598602\n\n\npsch_atlstba\ndouble\n0.32452780008316, NA, 0.192667931318283, 0.412142157554626, 0.439965158700943\n\n\npop_propurban\ndouble\n1, NA, 1, 1, 1\n\n\n\n\n\n\n\nSummary Statistics\nBelow is a summary of the numeric and categorical variables in the dataset:\n\n# Summary stats as a table\nsummary_stats &lt;- summary(df)\nkable(summary_stats, caption = \"Summary Statistics of All Variables\")\n\n\nSummary Statistics of All Variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\nask\naskd1\naskd2\naskd3\nask1\nask2\nask3\namount\ngave\namountchange\nhpa\nltmedmra\nfreq\nyears\nyear5\nmrm2\ndormant\nfemale\ncouple\nstate50one\nnonlit\ncases\nstatecnt\nstateresponse\nstateresponset\nstateresponsec\nstateresponsetminc\nperbush\nclose25\nred0\nblue0\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n\nMin. :0.0000\nMin. :0.0000\nMin. :0.000\nMin. :0.0000\nMin. :0.0000\nMin. :0.000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. :0.000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. : 25.0\nMin. : 35.00\nMin. : 50\nMin. : 0.0000\nMin. :0.00000\nMin. :-200412.12\nMin. : 0.00\nMin. :0.0000\nMin. : 0.000\nMin. : 0.000\nMin. :0.0000\nMin. : 0.00\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000000\nMin. :0.000\nMin. :0.0\nMin. : 0.001995\nMin. :0.00000\nMin. :0.00000\nMin. :0.00000\nMin. :-0.047619\nMin. :0.09091\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0094\nMin. :0.0000\nMin. :0.0000\nMin. :0.000\nMin. : 5000\nMin. :0.0000\nMin. :0.0000\nMin. :0.0000\n\n\n\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.: 35.0\n1st Qu.: 45.00\n1st Qu.: 55\n1st Qu.: 0.0000\n1st Qu.:0.00000\n1st Qu.: -50.00\n1st Qu.: 30.00\n1st Qu.:0.0000\n1st Qu.: 2.000\n1st Qu.: 2.000\n1st Qu.:0.0000\n1st Qu.: 4.00\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000000\n1st Qu.:1.000\n1st Qu.:1.0\n1st Qu.: 1.833234\n1st Qu.:0.01816\n1st Qu.:0.01849\n1st Qu.:0.01286\n1st Qu.:-0.001388\n1st Qu.:0.44444\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:0.7558\n1st Qu.:0.0147\n1st Qu.:0.2583\n1st Qu.:2.210\n1st Qu.: 39181\n1st Qu.:0.5602\n1st Qu.:0.2356\n1st Qu.:0.8849\n\n\n\nMedian :1.0000\nMedian :0.0000\nMedian :1.000\nMedian :0.0000\nMedian :0.0000\nMedian :2.000\nMedian :0.0000\nMedian :0.0000\nMedian :0.0000\nMedian :0.0000\nMedian :1.000\nMedian :0.0000\nMedian :0.0000\nMedian :0.0000\nMedian : 45.0\nMedian : 60.00\nMedian : 70\nMedian : 0.0000\nMedian :0.00000\nMedian : -30.00\nMedian : 45.00\nMedian :0.0000\nMedian : 4.000\nMedian : 5.000\nMedian :1.0000\nMedian : 8.00\nMedian :1.0000\nMedian :0.0000\nMedian :0.0000\nMedian :0.0000000\nMedian :3.000\nMedian :1.0\nMedian : 3.538799\nMedian :0.01971\nMedian :0.02170\nMedian :0.01988\nMedian : 0.001779\nMedian :0.48485\nMedian :0.0000\nMedian :0.0000\nMedian :1.0000\nMedian :1.0000\nMedian :0.0000\nMedian :0.8728\nMedian :0.0366\nMedian :0.3055\nMedian :2.440\nMedian : 50673\nMedian :0.7123\nMedian :0.3737\nMedian :1.0000\n\n\n\nMean :0.6668\nMean :0.3332\nMean :1.334\nMean :0.2223\nMean :0.2222\nMean :1.667\nMean :0.1667\nMean :0.1666\nMean :0.1667\nMean :0.1667\nMean :1.334\nMean :0.2223\nMean :0.2223\nMean :0.2222\nMean : 71.5\nMean : 91.79\nMean : 111\nMean : 0.9157\nMean :0.02065\nMean : -52.67\nMean : 59.38\nMean :0.4937\nMean : 8.039\nMean : 6.098\nMean :0.5088\nMean : 13.01\nMean :0.5235\nMean :0.2777\nMean :0.0919\nMean :0.0009983\nMean :2.474\nMean :1.5\nMean : 5.998820\nMean :0.02063\nMean :0.02199\nMean :0.01772\nMean : 0.004273\nMean :0.48794\nMean :0.1857\nMean :0.4044\nMean :0.5956\nMean :0.5102\nMean :0.4887\nMean :0.8196\nMean :0.0867\nMean :0.3217\nMean :2.429\nMean : 54816\nMean :0.6694\nMean :0.3917\nMean :0.8720\n\n\n\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:2.000\n3rd Qu.:0.0000\n3rd Qu.:0.0000\n3rd Qu.:3.000\n3rd Qu.:0.0000\n3rd Qu.:0.0000\n3rd Qu.:0.0000\n3rd Qu.:0.0000\n3rd Qu.:2.000\n3rd Qu.:0.0000\n3rd Qu.:0.0000\n3rd Qu.:0.0000\n3rd Qu.: 65.0\n3rd Qu.: 85.00\n3rd Qu.: 100\n3rd Qu.: 0.0000\n3rd Qu.:0.00000\n3rd Qu.: -25.00\n3rd Qu.: 60.00\n3rd Qu.:1.0000\n3rd Qu.: 10.000\n3rd Qu.: 9.000\n3rd Qu.:1.0000\n3rd Qu.: 19.00\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:0.0000\n3rd Qu.:0.0000000\n3rd Qu.:4.000\n3rd Qu.:2.0\n3rd Qu.: 9.607021\n3rd Qu.:0.02305\n3rd Qu.:0.02470\n3rd Qu.:0.02081\n3rd Qu.: 0.010545\n3rd Qu.:0.52525\n3rd Qu.:0.0000\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:0.9388\n3rd Qu.:0.0909\n3rd Qu.:0.3691\n3rd Qu.:2.660\n3rd Qu.: 66005\n3rd Qu.:0.8168\n3rd Qu.:0.5300\n3rd Qu.:1.0000\n\n\n\nMax. :1.0000\nMax. :1.0000\nMax. :3.000\nMax. :1.0000\nMax. :1.0000\nMax. :4.000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :3.000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :1500.0\nMax. :1875.00\nMax. :2250\nMax. :400.0000\nMax. :1.00000\nMax. : 275.00\nMax. :1000.00\nMax. :1.0000\nMax. :218.000\nMax. :95.000\nMax. :1.0000\nMax. :168.00\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000000\nMax. :6.000\nMax. :4.0\nMax. :17.368841\nMax. :0.07692\nMax. :0.11111\nMax. :0.05263\nMax. : 0.111111\nMax. :0.73196\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\nMax. :0.9896\nMax. :0.9975\nMax. :5.270\nMax. :200001\nMax. :1.0000\nMax. :1.0000\nMax. :1.0000\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA’s :1\nNA\nNA’s :1\nNA\nNA’s :1111\nNA’s :1148\nNA\nNA’s :452\nNA’s :452\nNA\nNA\nNA\nNA’s :3\nNA’s :3\nNA’s :35\nNA’s :35\nNA’s :35\nNA’s :35\nNA’s :105\nNA’s :105\nNA’s :1866\nNA’s :2036\nNA’s :1866\nNA’s :1862\nNA’s :1874\nNA’s :1869\nNA’s :1868\nNA’s :1866\n\n\n\n\n\n\n\nMissing and Unique Values\nThis table shows the number of missing values and unique values for each column:\n\nmissing_unique &lt;- df %&gt;%\n  summarise(across(everything(), list(\n    missing = ~sum(is.na(.)),\n    unique = ~n_distinct(.)\n  )))\n\nkable(missing_unique, caption = \"Missing Values and Unique Counts per Variable\")\n\n\nMissing Values and Unique Counts per Variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment_missing\ntreatment_unique\ncontrol_missing\ncontrol_unique\nratio_missing\nratio_unique\nratio2_missing\nratio2_unique\nratio3_missing\nratio3_unique\nsize_missing\nsize_unique\nsize25_missing\nsize25_unique\nsize50_missing\nsize50_unique\nsize100_missing\nsize100_unique\nsizeno_missing\nsizeno_unique\nask_missing\nask_unique\naskd1_missing\naskd1_unique\naskd2_missing\naskd2_unique\naskd3_missing\naskd3_unique\nask1_missing\nask1_unique\nask2_missing\nask2_unique\nask3_missing\nask3_unique\namount_missing\namount_unique\ngave_missing\ngave_unique\namountchange_missing\namountchange_unique\nhpa_missing\nhpa_unique\nltmedmra_missing\nltmedmra_unique\nfreq_missing\nfreq_unique\nyears_missing\nyears_unique\nyear5_missing\nyear5_unique\nmrm2_missing\nmrm2_unique\ndormant_missing\ndormant_unique\nfemale_missing\nfemale_unique\ncouple_missing\ncouple_unique\nstate50one_missing\nstate50one_unique\nnonlit_missing\nnonlit_unique\ncases_missing\ncases_unique\nstatecnt_missing\nstatecnt_unique\nstateresponse_missing\nstateresponse_unique\nstateresponset_missing\nstateresponset_unique\nstateresponsec_missing\nstateresponsec_unique\nstateresponsetminc_missing\nstateresponsetminc_unique\nperbush_missing\nperbush_unique\nclose25_missing\nclose25_unique\nred0_missing\nred0_unique\nblue0_missing\nblue0_unique\nredcty_missing\nredcty_unique\nbluecty_missing\nbluecty_unique\npwhite_missing\npwhite_unique\npblack_missing\npblack_unique\npage18_39_missing\npage18_39_unique\nave_hh_sz_missing\nave_hh_sz_unique\nmedian_hhincome_missing\nmedian_hhincome_unique\npowner_missing\npowner_unique\npsch_atlstba_missing\npsch_atlstba_unique\npop_propurban_missing\npop_propurban_unique\n\n\n\n\n0\n2\n0\n2\n0\n4\n0\n2\n0\n2\n0\n5\n0\n2\n0\n2\n0\n2\n0\n2\n0\n4\n0\n2\n0\n2\n0\n2\n0\n18\n0\n18\n0\n18\n0\n43\n0\n2\n0\n240\n0\n243\n0\n2\n0\n144\n1\n23\n0\n2\n1\n68\n0\n2\n1111\n3\n1148\n3\n0\n2\n452\n8\n452\n6\n0\n57\n0\n48\n0\n47\n3\n42\n3\n50\n35\n42\n35\n3\n35\n3\n35\n3\n105\n3\n105\n3\n1866\n10730\n2036\n10541\n1866\n10789\n1862\n297\n1874\n9570\n1869\n10795\n1868\n10791\n1866\n5608\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code"
  },
  {
    "objectID": "blog/hw1_questions.html#experimental-results",
    "href": "blog/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n# Display results\nkable(results_combined, caption = \"Balance Test: Manual T-Tests vs Linear Regression\",\n      digits = 3)\n\n\nBalance Test: Manual T-Tests vs Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\ngroup1_mean\ngroup2_mean\nmean_diff\nse\nt_stat\nreg_estimate\nreg_se\nreg_t_stat\n\n\n\n\nmrm2\n13.012\n12.998\n0.014\n0.114\n0.120\n0.014\n0.115\n0.119\n\n\nyears\n6.078\n6.136\n-0.058\n0.053\n-1.091\n-0.058\n0.052\n-1.103\n\n\nfreq\n8.035\n8.047\n-0.012\n0.108\n-0.111\n-0.012\n0.108\n-0.111\n\n\n\n\n\nThe balance test results shown above compare key baseline characteristics across the treatment and control groups. Specifically, I tested three variables—mrm2 (months since last donation), years (years since initial donation), and freq (number of prior donations)—to assess whether the treatment and control groups are statistically significantly different from one another.\nIn all three cases, the difference in means between the two groups is extremely small, and the associated t-statistics are all very close to zero, well below the critical value for 95% significance. These results are confirmed by linear regressions of each variable on the treatment indicator, which yield the exact same estimates and test statistics as the manual t-tests—demonstrating analytical consistency.\nThese findings suggest that the random assignment worked as intended, and there are no systematic differences between treatment and control groups on these pre-treatment variables. This supports the internal validity of the experimental design."
  },
  {
    "objectID": "blog/hw1_questions.html#simulation-experiment",
    "href": "blog/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nSimulated Sampling Distribution of ATE (Average Treatment Effect)\n\nlibrary(tidyverse)\n\n# Pull full donation amount vectors\ntreat &lt;- df %&gt;% filter(treatment == 1) %&gt;% pull(amount)\ncontrol &lt;- df %&gt;% filter(treatment == 0) %&gt;% pull(amount)\n\n# Set sample size per experiment\nn &lt;- 100  # sample size per group per experiment\n\n# Simulate 10,000 experiments\nset.seed(42)\nn_sim &lt;- 10000\ndiffs &lt;- replicate(n_sim, {\n  t_sample &lt;- sample(treat, n, replace = TRUE)\n  c_sample &lt;- sample(control, n, replace = TRUE)\n  mean(t_sample) - mean(c_sample)\n})\n\n# Compute cumulative average of differences\ncum_avg &lt;- cumsum(diffs) / seq_along(diffs)\ntrue_diff &lt;- mean(treat) - mean(control)\n\n# Plot it\ntibble(iteration = 1:n_sim, cum_avg = cum_avg) %&gt;%\n  ggplot(aes(x = iteration, y = cum_avg)) +\n  geom_line(color = \"steelblue\", linewidth = 1) +\n  geom_hline(yintercept = true_diff, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(\n    title = \"Convergence of Estimated ATE Over Simulated Experiments\",\n    x = \"Simulation Number\",\n    y = \"Cumulative Average Treatment Effect\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis plot visualizes the convergence of estimated treatment effects over 10,000 simulated randomized experiments. In each simulation, we draw a fresh random sample of 100 units from both the treatment and control groups and compute the difference in average donation amounts. The blue line shows the cumulative average of these estimates across simulations, and the dashed red line represents the true difference in the full dataset. As expected, the cumulative average stabilizes around the true value as the number of simulations increases. This demonstrates the Law of Large Numbers in action and shows how sampling variability decreases with repeated estimation, reinforcing the reliability of our causal estimate under random assignment.\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load your dataset (make sure the path works in your environment)\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Prepare data\ntreat = df[df[\"treatment\"] == 1][\"amount\"].dropna().values\ncontrol = df[df[\"treatment\"] == 0][\"amount\"].dropna().values\n\nsample_sizes = [50, 200, 500, 1000]\ntrue_diff = np.mean(treat) - np.mean(control)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nnp.random.seed(123)\nfor i, n in enumerate(sample_sizes):\n    diffs = [np.mean(np.random.choice(treat, n, replace=True)) -\n             np.mean(np.random.choice(control, n, replace=True)) for _ in range(1000)]\n    \n    ax = axes[i]\n    sns.histplot(diffs, bins=30, kde=True, color=\"skyblue\", ax=ax)\n    ax.axvline(0, color=\"red\", linestyle=\"--\", linewidth=1.2, label=\"Zero\")\n    ax.axvline(true_diff, color=\"green\", linestyle=\"--\", linewidth=1.2, label=\"True Diff\")\n    ax.set_title(f\"Sample size = {n}\")\n    ax.set_xlabel(\"Estimated Treatment Effect\")\n    ax.set_ylabel(\"Count\")\n\naxes[0].legend()\nfig.suptitle(\"Central Limit Theorem: Distribution of Mean Differences\", fontsize=16)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\nObservations:\nAt n = 50: The distribution is wide and noisy, and zero is close to the center — we often estimate a treatment effect near zero just by chance. The green line is close, but it’s hard to distinguish from noise.\nAt n = 200: The distribution narrows slightly, and the green line (true effect) starts pulling away from zero. However, there’s still a decent chance of drawing a sample where zero falls near the center of the distribution.\nAt n = 500 and 1000: The distribution becomes tight and centered around the true effect. The red line (zero) is now clearly in the tails, suggesting that it’s very unlikely for a large random sample to produce an estimate near zero if a true treatment effect exists.\n\n\nConclusion:\nAs sample size increases, the sampling distribution of the estimated treatment effect becomes more concentrated around the true value, and the probability of observing a misleading result (like a difference close to zero when there is a real effect) diminishes. This demonstrates the precision and reliability gained from larger samples, as predicted by the Central Limit Theorem."
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is Project 2",
    "section": "",
    "text": "This is Project 2"
  },
  {
    "objectID": "blog/hw1_questions.html#table-1-matters",
    "href": "blog/hw1_questions.html#table-1-matters",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Table 1 Matters",
    "text": "Table 1 Matters\nTable 1 in the original Karlan and List (2007) paper serves a critical diagnostic purpose. It provides summary statistics for a wide range of baseline variables, broken down by treatment and control groups, including demographic, behavioral, and geographic characteristics. Its role is to demonstrate balance across groups, validating the assumption that any differences in outcomes can be causally attributed to the treatment rather than pre-existing differences.\nBy comparing your balance test results to Table 1:\nYou can confirm that your replication dataset matches the original in both structure and balance.\nYour t-test and regression results on mrm2, years, and freq closely align with the reported means in Table 1.\nLike in Table 1, you find no statistically significant differences—reinforcing that the randomization mechanism was successful.\nIn short, Table 1 provides the foundational evidence that the experimental groups are statistically equivalent at baseline. Your balance test serves the same function, and by mirroring that analysis, you’re showing your replication is on solid footing.\n\nReference: Karlan and List (2007)\nHere is the PDF of the original study and includes Table 1, which summarizes the balance between treatment and control groups:\nYou can also download the PDF here.\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/hw1_questions.html#balance-test",
    "href": "blog/hw1_questions.html#balance-test",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Test",
    "text": "Balance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nBalance Testing on Pre-Treatment Variables\n\n# Load necessary libraries\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(broom)\n  library(knitr)\n})\n\n# Manual t-test function using class formula\nmanual_t_test &lt;- function(var, group_var, group1 = 1, group2 = 0, data) {\n  x1 &lt;- data[[var]][data[[group_var]] == group1]\n  x2 &lt;- data[[var]][data[[group_var]] == group2]\n\n  x1 &lt;- x1[!is.na(x1)]\n  x2 &lt;- x2[!is.na(x2)]\n\n  n1 &lt;- length(x1)\n  n2 &lt;- length(x2)\n  m1 &lt;- mean(x1)\n  m2 &lt;- mean(x2)\n  s1 &lt;- var(x1)\n  s2 &lt;- var(x2)\n\n  se_diff &lt;- sqrt(s1 / n1 + s2 / n2)\n  t_stat &lt;- (m1 - m2) / se_diff\n\n  tibble(\n    variable = var,\n    group1_mean = m1,\n    group2_mean = m2,\n    mean_diff = m1 - m2,\n    se = se_diff,\n    t_stat = t_stat\n  )\n}\n\n# Variables to test\ntest_vars &lt;- c(\"mrm2\", \"years\", \"freq\")\n\n# Run manual t-tests\nt_test_results &lt;- map_dfr(test_vars, ~manual_t_test(.x, \"treatment\", data = df))\n\n# Run regressions and extract treatment coefficient\nregression_results &lt;- map_dfr(test_vars, function(var) {\n  mod &lt;- lm(as.formula(paste(var, \"~ treatment\")), data = df)\n  tidy(mod) %&gt;%\n    filter(term == \"treatment\") %&gt;%\n    mutate(variable = var) %&gt;%\n    select(variable, estimate, std.error, statistic)\n})\n\n# Merge results\nresults_combined &lt;- left_join(\n  t_test_results,\n  regression_results,\n  by = \"variable\"\n) %&gt;%\n  rename(\n    reg_estimate = estimate,\n    reg_se = std.error,\n    reg_t_stat = statistic\n  )\n\n\n\nExperimental Results\n\n\n\nBalance Test: Manual T-Tests vs Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\ngroup1_mean\ngroup2_mean\nmean_diff\nse\nt_stat\nreg_estimate\nreg_se\nreg_t_stat\n\n\n\n\nmrm2\n13.012\n12.998\n0.014\n0.114\n0.120\n0.014\n0.115\n0.119\n\n\nyears\n6.078\n6.136\n-0.058\n0.053\n-1.091\n-0.058\n0.052\n-1.103\n\n\nfreq\n8.035\n8.047\n-0.012\n0.108\n-0.111\n-0.012\n0.108\n-0.111\n\n\n\n\n\nThe balance test results shown above compare key baseline characteristics across the treatment and control groups. Specifically, I tested three variables—mrm2 (months since last donation), years (years since initial donation), and freq (number of prior donations)—to assess whether the treatment and control groups are statistically significantly different from one another.\nIn all three cases, the difference in means between the two groups is extremely small, and the associated t-statistics are all very close to zero, well below the critical value for 95% significance. These results are confirmed by linear regressions of each variable on the treatment indicator, which yield the exact same estimates and test statistics as the manual t-tests—demonstrating analytical consistency.\nThese findings suggest that the random assignment worked as intended, and there are no systematic differences between treatment and control groups on these pre-treatment variables. This supports the internal validity of the experimental design.\n\nConclusion: Corresponds to Results in Table 1\nTable 1 in the original Karlan and List (2007) paper serves a critical diagnostic purpose. It provides summary statistics for a wide range of baseline variables, broken down by treatment and control groups, including demographic, behavioral, and geographic characteristics. Its role is to demonstrate balance across groups, validating the assumption that any differences in outcomes can be causally attributed to the treatment rather than pre-existing differences.\nBy comparing your balance test results to Table 1:\nYou can confirm that your replication dataset matches the original in both structure and balance.\nYour t-test and regression results on mrm2, years, and freq closely align with the reported means in Table 1.\nLike in Table 1, you find no statistically significant differences—reinforcing that the randomization mechanism was successful.\nIn short, Table 1 provides the foundational evidence that the experimental groups are statistically equivalent at baseline. Your balance test serves the same function, and by mirroring that analysis, you’re showing your replication is on solid footing.\n\nReference: Karlan and List (2007)\nHere is the PDF of the original study and includes Table 1, which summarizes the balance between treatment and control groups:\nYou can also download the PDF here.\n\n\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\nDonation Rate by Treatment Status\n\nlibrary(tidyverse)\n\n# Calculate donation proportions\ndonation_rate &lt;- df %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(prop_donated = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(group = if_else(treatment == 1, \"Treatment\", \"Control\"))\n\n# Ensure control is first\ndonation_rate$group &lt;- factor(donation_rate$group, levels = c(\"Control\", \"Treatment\"))\n\n# Plot with zoomed y-axis (proportions, not percent)\nggplot(donation_rate, aes(x = group, y = prop_donated)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Proportion of Donors by Treatment Group\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_y_continuous(limits = c(0, 0.03)) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\nEffect of Treatment on Donation Behavior\n\n# Load required libraries\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(broom)\n  library(knitr)\n})\n\n# Manual t-test using class formula\ntreat &lt;- df$gave[df$treatment == 1]\nctrl &lt;- df$gave[df$treatment == 0]\n\n# Remove missing\ntreat &lt;- na.omit(treat)\nctrl &lt;- na.omit(ctrl)\n\n# Compute values\nmean_treat &lt;- mean(treat)\nmean_ctrl &lt;- mean(ctrl)\nn1 &lt;- length(treat)\nn0 &lt;- length(ctrl)\nvar1 &lt;- var(treat)\nvar0 &lt;- var(ctrl)\n\nse_diff &lt;- sqrt(var1 / n1 + var0 / n0)\nt_stat &lt;- (mean_treat - mean_ctrl) / se_diff\n\n# Assemble t-test result\nt_test_result &lt;- tibble(\n  `Mean (Treatment)` = mean_treat,\n  `Mean (Control)` = mean_ctrl,\n  `Difference` = mean_treat - mean_ctrl,\n  `Std. Error` = se_diff,\n  `T-Statistic` = t_stat\n)\n\n# Run regression\nreg_model &lt;- lm(gave ~ treatment, data = df)\nreg_summary &lt;- tidy(reg_model) %&gt;%\n  filter(term == \"treatment\") %&gt;%\n  select(`Coefficient` = estimate,\n         `Std. Error` = std.error,\n         `T-Statistic` = statistic,\n         `P-Value` = p.value)\n\n# Output formatted tables\nkable(t_test_result, caption = \"Manual T-Test: Effect of Treatment on Donations\", digits = 4)\n\n\nManual T-Test: Effect of Treatment on Donations\n\n\nMean (Treatment)\nMean (Control)\nDifference\nStd. Error\nT-Statistic\n\n\n\n\n0.022\n0.0179\n0.0042\n0.0013\n3.2095\n\n\n\n\nkable(reg_summary, caption = \"Linear Regression: Coefficient on Treatment\", digits = 4)\n\n\nLinear Regression: Coefficient on Treatment\n\n\nCoefficient\nStd. Error\nT-Statistic\nP-Value\n\n\n\n\n0.0042\n0.0013\n3.1014\n0.0019\n\n\n\n\n\nThe analysis shows that individuals in the treatment group—those who received a message mentioning matched donations—were more likely to donate than those in the control group. The difference in donation rates is small in absolute terms (about 0.4 percentage points), but statistically significant. Both the manual t-test and the linear regression confirm this result, with t-statistics above 3 and a p-value well below the 5% significance threshold.\nIn practical terms, this suggests that even a subtle change in messaging—like telling donors their gift will be matched—can meaningfully affect behavior. People appear to be motivated by the idea that their donation will go further, or that someone else values their contribution enough to match it. This reflects broader behavioral principles such as reciprocity, social influence, and the perceived value of impact.\nOverall, the findings support the conclusion that matching offers are an effective strategy in charitable fundraising, nudging more people to take action even when the individual gain is not large. This result is consistent with what is reported in Table 2a, Panel A of the original Karlan and List (2007) paper.\n\n\nProbit Regression: Effect of Treatment on Donation\n\n# Load required libraries\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(broom)\n})\n\n# Run probit regression\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = df)\n\n# Tidy output\nprobit_summary &lt;- tidy(probit_model)\n\n# Show results in table\nlibrary(knitr)\nkable(probit_summary, caption = \"Probit Regression: Outcome = Gave, Predictor = Treatment\", digits = 4)\n\n\nProbit Regression: Outcome = Gave, Predictor = Treatment\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.1001\n0.0233\n-90.0739\n0.0000\n\n\ntreatment\n0.0868\n0.0279\n3.1130\n0.0019\n\n\n\n\n\nThe probit regression estimates the effect of being assigned to the treatment group on the probability of making a donation. The coefficient on the treatment variable is positive and statistically significant, closely matching the result reported in Table 3, Column 1 of Karlan and List (2007).\nIn practical terms, this confirms that simply offering a matching grant—without changing anything else about the appeal—significantly increases the likelihood that someone donates. While the actual donation rates remain low, this small but consistent shift in probability reflects how subtle cues in messaging can have real behavioral impact. The probit model accounts for the nonlinear relationship between predictors and a binary outcome, and still finds that the treatment has a meaningful effect.\nThis reinforces the key insight of the paper: people are more likely to act generously when they believe their contribution will be leveraged or matched, even in a large, field-based real-world setting.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\nEffect of Match Size on Donation (T-Tests)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# Filter treatment group and relabel ratio values\ndf_treat &lt;- df %&gt;%\n  filter(treatment == 1) %&gt;%\n  mutate(ratio = as.character(ratio)) %&gt;%\n  mutate(ratio_label = case_when(\n    ratio == \"1\" ~ \"1:1\",\n    ratio == \"2\" ~ \"2:1\",\n    ratio == \"3\" ~ \"3:1\",\n    TRUE ~ NA_character_\n  ))\n\n# Safe t-test function\ncompare_match_rates &lt;- function(group1, group2, data) {\n  x1 &lt;- na.omit(data$gave[data$ratio_label == group1])\n  x2 &lt;- na.omit(data$gave[data$ratio_label == group2])\n\n  if (length(x1) &lt; 5 | length(x2) &lt; 5) {\n    return(tibble(\n      comparison = paste(group1, \"vs\", group2),\n      estimate1 = NA, estimate2 = NA, statistic = NA,\n      p.value = NA, conf.low = NA, conf.high = NA\n    ))\n  }\n\n  t.test(x1, x2, var.equal = TRUE) %&gt;%\n    tidy() %&gt;%\n    mutate(comparison = paste(group1, \"vs\", group2)) %&gt;%\n    select(comparison, estimate1, estimate2,\n           statistic, p.value, conf.low, conf.high)\n}\n\n# Run all 3 comparisons\nresults &lt;- bind_rows(\n  compare_match_rates(\"1:1\", \"2:1\", df_treat),\n  compare_match_rates(\"2:1\", \"3:1\", df_treat),\n  compare_match_rates(\"1:1\", \"3:1\", df_treat)\n)\n\n# Output results\nkable(results, caption = \"Pairwise T-Tests: Donation Rates by Match Size\", digits = 4)\n\n\nPairwise T-Tests: Donation Rates by Match Size\n\n\n\n\n\n\n\n\n\n\n\ncomparison\nestimate1\nestimate2\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n1:1 vs 2:1\n0.0207\n0.0226\n-0.9650\n0.3345\n-0.0057\n0.0019\n\n\n2:1 vs 3:1\n0.0226\n0.0227\n-0.0501\n0.9600\n-0.0040\n0.0038\n\n\n1:1 vs 3:1\n0.0207\n0.0227\n-1.0150\n0.3101\n-0.0058\n0.0018\n\n\n\n\n\nOn page 8, Karlan and List (2007) write:\n“…the figures suggest that larger match ratios are not necessarily more effective.”\nThe results support this observation: even though the match ratios increase from 1:1 to 3:1, the donation rates barely change, and the differences are not statistically significant. The marginal value of increasing the match ratio appears to be negligible.\nThis suggests that it’s the presence of a match offer that matters—not the size of the match. Once donors know their gift will be matched, making it a 2:1 or 3:1 offer doesn’t significantly change their likelihood to give.\n\n\nRegression: Effect of Match Ratio Size on Donation\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# Create dummy variables for match ratios (treatment only)\ndf &lt;- df %&gt;%\n  mutate(\n    ratio = as.character(ratio),\n    ratio1 = as.integer(ratio == \"1\"),\n    ratio2 = as.integer(ratio == \"2\"),\n    ratio3 = as.integer(ratio == \"3\")\n  )\n\n# Run regression using ratio1, ratio2, ratio3 (baseline is control group)\nmatch_lm &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = df)\n\n# Tidy and print results\nmatch_lm_tidy &lt;- tidy(match_lm)\n\nkable(match_lm_tidy, caption = \"Regression: Effect of Match Ratio on Donation (Baseline = Control)\", digits = 4)\n\n\nRegression: Effect of Match Ratio on Donation (Baseline = Control)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0179\n0.0011\n16.2245\n0.0000\n\n\nratio1\n0.0029\n0.0017\n1.6615\n0.0966\n\n\nratio2\n0.0048\n0.0017\n2.7445\n0.0061\n\n\nratio3\n0.0049\n0.0017\n2.8016\n0.0051\n\n\n\n\n\n\nKey Findings:\nControl group baseline: 1.79% donation rate (Intercept)\n1:1 match: Increases donation rate by ~0.29 percentage points (not statistically significant, p = 0.097)\n2:1 match: Increases donation rate by ~0.48 points (statistically significant, p = 0.0061)\n3:1 match: Similar increase as 2:1 (~0.49 points), also statistically significant (p = 0.0051)\nThe presence of any match offer increases the probability of donating, but interestingly, larger match ratios (2:1 and 3:1) are more effective than 1:1. This differs slightly from the earlier t-tests (which found no significant differences between match sizes), but the regression shows that the increase in donation probability for 2:1 and 3:1 offers is statistically significant compared to control.\nThat said, the difference between 2:1 and 3:1 is very small, and the coefficients are nearly identical, reinforcing the earlier point: increasing the match size beyond 2:1 might not yield additional behavioral gains.\nThe regression results show that larger match ratios (2:1 and 3:1) significantly increase the likelihood of donating relative to no match, while the 1:1 match is only marginally effective. However, the impact of 2:1 and 3:1 matches is nearly identical, suggesting that while higher match ratios can enhance giving, the effect appears to plateau beyond 2:1. This nuance helps explain why the authors state that “larger match ratios are not necessarily more effective” (p. 8)—the increase from 1:1 to 2:1 matters, but going from 2:1 to 3:1 doesn’t do much more.\n\n\n\nDifferences in Match Size Effects: Raw vs Fitted\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# Filter treatment group and clean up ratio variable\ndf_treat &lt;- df %&gt;%\n  filter(treatment == 1) %&gt;%\n  mutate(ratio = as.character(ratio))\n\n# Calculate raw response rates by ratio\nraw_rates &lt;- df_treat %&gt;%\n  filter(ratio %in% c(\"1\", \"2\", \"3\")) %&gt;%\n  group_by(ratio) %&gt;%\n  summarise(response_rate = mean(gave, na.rm = TRUE)) %&gt;%\n  pivot_wider(names_from = ratio, values_from = response_rate) %&gt;%\n  rename(`1:1` = `1`, `2:1` = `2`, `3:1` = `3`) %&gt;%\n  mutate(\n    raw_diff_2v1 = `2:1` - `1:1`,\n    raw_diff_3v2 = `3:1` - `2:1`\n  )\n\n# Pull regression estimates\nreg_diffs &lt;- match_lm_tidy %&gt;%\n  filter(term %in% c(\"ratio1\", \"ratio2\", \"ratio3\")) %&gt;%\n  select(term, estimate) %&gt;%\n  pivot_wider(names_from = term, values_from = estimate) %&gt;%\n  mutate(\n    fitted_diff_2v1 = ratio2 - ratio1,\n    fitted_diff_3v2 = ratio3 - ratio2\n  )\n\n# Combine raw + regression diff output\ncomparison &lt;- bind_cols(\n  raw_rates %&gt;% select(raw_diff_2v1, raw_diff_3v2),\n  reg_diffs %&gt;% select(fitted_diff_2v1, fitted_diff_3v2)\n)\n\nkable(comparison, caption = \"Difference in Response Rates: Raw vs Fitted Coefficients\", digits = 4)\n\n\nDifference in Response Rates: Raw vs Fitted Coefficients\n\n\nraw_diff_2v1\nraw_diff_3v2\nfitted_diff_2v1\nfitted_diff_3v2\n\n\n\n\n0.0019\n1e-04\n0.0019\n1e-04\n\n\n\n\n\nBoth the raw data and the regression coefficients show that increasing the match from 1:1 to 2:1 leads to a small but noticeable increase in donation rates. However, increasing the match further to 3:1 provides no meaningful gain. This supports the authors’ suggestion that higher match ratios do not necessarily produce better outcomes. In essence, the presence of a match offer matters—but making that match larger beyond a certain point (2:1) does not meaningfully change donor behavior. This has important practical implications: organizations may not need to offer higher matches to motivate giving, as the psychological effect appears to plateau.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n\nEffect of Treatment on Donation Amount (Full Sample)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# T-test: donation amount by treatment\ntt &lt;- t.test(amount ~ treatment, data = df)\n\n# Format t-test result\ntt_df &lt;- tidy(tt) %&gt;%\n  mutate(\n    estimate1 = tt$estimate[1],\n    estimate2 = tt$estimate[2]\n  ) %&gt;%\n  select(estimate1, estimate2, estimate, statistic, p.value, conf.low, conf.high)\n\n# Regression: amount ~ treatment\nlm_amt &lt;- lm(amount ~ treatment, data = df)\nlm_df &lt;- tidy(lm_amt) %&gt;%\n  filter(term == \"treatment\")\n\n# Output both tables\nkable(tt_df, caption = \"T-Test: Effect of Treatment on Donation Amount\", digits = 4)\n\n\nT-Test: Effect of Treatment on Donation Amount\n\n\n\n\n\n\n\n\n\n\n\nestimate1\nestimate2\nestimate\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n0.8133\n0.9669\n-0.1536\n-1.9183\n0.0551\n-0.3106\n0.0033\n\n\n\n\nkable(lm_df, caption = \"Regression: Treatment Effect on Donation Amount\", digits = 4)\n\n\nRegression: Treatment Effect on Donation Amount\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\ntreatment\n0.1536\n0.0826\n1.8605\n0.0628\n\n\n\n\n\nThe difference is about $0.15 higher in the treatment group.\nThe t-test p-value is 0.0551, just slightly above the 5% threshold.\nThe regression gives nearly identical results: estimate = 0.1536, p = 0.0628\n\nResults Summary\nThe treatment group gave more on average, but the difference is not statistically significant at the 5% level—it’s just above the line. While this might suggest that match offers increase total donation amounts, the evidence is not strong enough to confidently claim a real effect at conventional significance levels.\n\n\n\nTreatment Effect on Donation Amount (Among Donors Only)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# Filter to people who donated something\ndf_donors &lt;- df %&gt;% filter(gave == 1)\n\n# T-test\ntt_donors &lt;- t.test(amount ~ treatment, data = df_donors)\n\n# Format t-test output\ntt_donors_df &lt;- tidy(tt_donors) %&gt;%\n  mutate(\n    estimate1 = tt_donors$estimate[1],\n    estimate2 = tt_donors$estimate[2]\n  ) %&gt;%\n  select(estimate1, estimate2, estimate, statistic, p.value, conf.low, conf.high)\n\n# Regression\nlm_donors &lt;- lm(amount ~ treatment, data = df_donors)\nlm_donors_df &lt;- tidy(lm_donors) %&gt;%\n  filter(term == \"treatment\")\n\n# Output\nkable(tt_donors_df, caption = \"T-Test: Treatment Effect on Donation Amount (Donors Only)\", digits = 4)\n\n\nT-Test: Treatment Effect on Donation Amount (Donors Only)\n\n\n\n\n\n\n\n\n\n\n\nestimate1\nestimate2\nestimate\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n45.5403\n43.8719\n1.6684\n0.5846\n0.559\n-3.9372\n7.274\n\n\n\n\nkable(lm_donors_df, caption = \"Regression: Treatment Effect on Donation Amount (Donors Only)\", digits = 4)\n\n\nRegression: Treatment Effect on Donation Amount (Donors Only)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\ntreatment\n-1.6684\n2.8724\n-0.5808\n0.5615\n\n\n\n\n\nThe t-test p-value = 0.559\nThe regression p-value = 0.5615\nBoth show no statistically significant difference between treatment and control among donors.\n\nConclusion\nAmong people who chose to donate, those in the treatment group did not give more—in fact, they gave slightly less on average, though not by a statistically meaningful amount.\nLimiting the analysis to only those who donated, we find no statistically significant difference in average donation amount between the treatment and control groups. The treatment coefficient is not significant, and the observed difference (~$1.67) is small and negative. However, this regression does not have a causal interpretation because it conditions on giving—an outcome influenced by the treatment. Thus, while match offers may increase the number of donors, they do not appear to affect how much people give once they’ve already decided to donate\n\n\n\nDistribution of Donation Amounts (Among Donors Only)\n\nlibrary(tidyverse)\n\n# Filter donors only\ndonors_only &lt;- df %&gt;% filter(gave == 1)\n\n# Compute group means\ngroup_means &lt;- donors_only %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(avg = mean(amount, na.rm = TRUE))\n\n# Label treatment vs control\ndonors_only &lt;- donors_only %&gt;%\n  mutate(group = if_else(treatment == 1, \"Treatment\", \"Control\"))\n\n# Plot\nggplot(donors_only, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"white\") +\n  geom_vline(data = group_means %&gt;%\n               mutate(group = if_else(treatment == 1, \"Treatment\", \"Control\")),\n             aes(xintercept = avg), color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  facet_wrap(~ group, scales = \"free_y\") +\n  coord_cartesian(xlim = c(0, 200)) +\n  labs(\n    title = \"Distribution of Donation Amounts (Among Donors)\",\n    x = \"Donation Amount ($)\",\n    y = \"Count\"\n  ) +\n  theme_minimal(base_size = 14)"
  }
]